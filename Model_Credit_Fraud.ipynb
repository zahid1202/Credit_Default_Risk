{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from functools import reduce\n",
    "import re as re\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import warnings\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn_pandas import CategoricalImputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.multiclass import  OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multilabel_train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"DataSet/application_train.csv\")\n",
    "test = pd.read_csv(\"DataSet/application_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 45.00 MB\n",
      "Memory usage after optimization is: 14.60 MB\n",
      "Decreased by 67.6%\n",
      "Memory usage of dataframe is 286.23 MB\n",
      "Memory usage after optimization is: 92.38 MB\n",
      "Decreased by 67.7%\n"
     ]
    }
   ],
   "source": [
    "test = reduce_mem(test)\n",
    "train = reduce_mem(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I realize the CODE_GENDER==\"XNA\" (only 4 observations with TARGET of 0) doesn't show up in the test data, but it's messing up with the label encoder, so I droped them all along.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(index = train.loc[train.CODE_GENDER==\"XNA\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These 5 columns (['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'EMERGENCYSTATE_MODE']) are label encoded\n",
      "Dimensions before OneHotEncoding : (307507, 122)\n",
      "Dimensions after OneHotEncoding : (307507, 240)\n",
      "These 5 columns (['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'EMERGENCYSTATE_MODE']) are label encoded\n",
      "Dimensions before OneHotEncoding : (48744, 121)\n",
      "Dimensions after OneHotEncoding : (48744, 237)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>HOUSETYPE_MODE_block of flats</th>\n",
       "      <th>HOUSETYPE_MODE_specific housing</th>\n",
       "      <th>HOUSETYPE_MODE_terraced house</th>\n",
       "      <th>WALLSMATERIAL_MODE_Block</th>\n",
       "      <th>WALLSMATERIAL_MODE_Mixed</th>\n",
       "      <th>WALLSMATERIAL_MODE_Monolithic</th>\n",
       "      <th>WALLSMATERIAL_MODE_Others</th>\n",
       "      <th>WALLSMATERIAL_MODE_Panel</th>\n",
       "      <th>WALLSMATERIAL_MODE_Stone, brick</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>568800.0</td>\n",
       "      <td>20560.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>222768.0</td>\n",
       "      <td>17370.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>663264.0</td>\n",
       "      <td>69777.0</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>49018.5</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  NAME_CONTRACT_TYPE  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
       "0      100001                   0            0             0                1   \n",
       "1      100005                   0            1             0                1   \n",
       "2      100013                   0            1             1                1   \n",
       "3      100028                   0            0             0                1   \n",
       "4      100038                   0            1             1                0   \n",
       "\n",
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0             0          135000.0    568800.0      20560.5         450000.0   \n",
       "1             0           99000.0    222768.0      17370.0         180000.0   \n",
       "2             0          202500.0    663264.0      69777.0         630000.0   \n",
       "3             2          315000.0   1575000.0      49018.5        1575000.0   \n",
       "4             1          180000.0    625500.0      32067.0         625500.0   \n",
       "\n",
       "             ...              HOUSETYPE_MODE_block of flats  \\\n",
       "0            ...                                          1   \n",
       "1            ...                                          0   \n",
       "2            ...                                          0   \n",
       "3            ...                                          1   \n",
       "4            ...                                          0   \n",
       "\n",
       "   HOUSETYPE_MODE_specific housing  HOUSETYPE_MODE_terraced house  \\\n",
       "0                                0                              0   \n",
       "1                                0                              0   \n",
       "2                                0                              0   \n",
       "3                                0                              0   \n",
       "4                                0                              0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Block  WALLSMATERIAL_MODE_Mixed  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Monolithic  WALLSMATERIAL_MODE_Others  \\\n",
       "0                              0                          0   \n",
       "1                              0                          0   \n",
       "2                              0                          0   \n",
       "3                              0                          0   \n",
       "4                              0                          0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Panel  WALLSMATERIAL_MODE_Stone, brick  \\\n",
       "0                         0                                1   \n",
       "1                         0                                0   \n",
       "2                         0                                0   \n",
       "3                         1                                0   \n",
       "4                         0                                0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Wooden  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  \n",
       "\n",
       "[5 rows x 237 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode(df):\n",
    "    le = LabelEncoder()\n",
    "    oe = OneHotEncoder()\n",
    "    le_col=[]\n",
    "    for col in df:\n",
    "        if df[col].dtype ==\"object\":\n",
    "            if df[col].nunique()==2:\n",
    "                df[col].replace(np.nan, \"NAN\", inplace=True)\n",
    "                le_col.append(col)\n",
    "                le.fit(df[col])\n",
    "                df[col] = le.transform(df[col])\n",
    "    print(\"These {} columns ({}) are label encoded\".format(len(le_col), le_col))\n",
    "    print(\"Dimensions before OneHotEncoding : {}\".format(df.shape))\n",
    "    df = pd.get_dummies(df)\n",
    "    print(\"Dimensions after OneHotEncoding : {}\".format(df.shape))\n",
    "    \n",
    "    return df\n",
    "                \n",
    "train =encode(train)\n",
    "train.head()\n",
    "test = encode(test)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape of train data before alinging: (307507, 240) \n",
      " Shape of test data before alinging: (48744, 237)\n",
      " Shape of train data after alinging: (307507, 238) \n",
      " Shape of test data after alinging: (48744, 237)\n"
     ]
    }
   ],
   "source": [
    "def align(train, test):\n",
    "    \n",
    "    print(\" Shape of train data before alinging: {}\".format(train.shape),\"\\n\", \n",
    "         \"Shape of test data before alinging: {}\".format(test.shape))\n",
    "    target = train[\"TARGET\"]\n",
    "    train, test = train.align(test, join=\"inner\", axis =1)\n",
    "    train[\"TARGET\"] = target\n",
    "    print(\" Shape of train data after alinging: {}\".format(train.shape), \"\\n\", \n",
    "     \"Shape of test data after alinging: {}\".format(test.shape))\n",
    "    return train, test\n",
    "train, test = align(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_correction(df, feature = \"DAYS_EMPLOYED\", integer=365243):\n",
    "    df['Birth_ANOMALY'] = (df[feature]==integer).astype(int)\n",
    "\n",
    "    df[feature].replace({integer: np.nan}, inplace =True )\n",
    "    return df\n",
    "train = anomaly_correction(train, feature = \"DAYS_EMPLOYED\", integer=365243)\n",
    "test = anomaly_correction(test, feature = \"DAYS_EMPLOYED\", integer=365243)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the negative values for some features, which should be positive, into positive.\n",
    "train[[\"DAYS_EMPLOYED\",\"DAYS_BIRTH\"]] = train[[\"DAYS_EMPLOYED\",\"DAYS_BIRTH\"]].apply(lambda x: x*(-1))\n",
    "test[[\"DAYS_EMPLOYED\",\"DAYS_BIRTH\"]]= test[[\"DAYS_EMPLOYED\",\"DAYS_BIRTH\"]].apply(lambda x: x*(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negatively correlated features are:\n",
      " EXT_SOURCE_3                           -0.178925\n",
      "EXT_SOURCE_2                           -0.160471\n",
      "EXT_SOURCE_1                           -0.155318\n",
      "DAYS_BIRTH                             -0.078242\n",
      "DAYS_EMPLOYED                          -0.074957\n",
      "NAME_EDUCATION_TYPE_Higher education   -0.056593\n",
      "NAME_INCOME_TYPE_Pensioner             -0.046211\n",
      "ORGANIZATION_TYPE_XNA                  -0.045989\n",
      "Birth_ANOMALY                          -0.045989\n",
      "FLOORSMAX_AVG                          -0.044010\n",
      "FLOORSMAX_MEDI                         -0.043775\n",
      "FLOORSMAX_MODE                         -0.043233\n",
      "HOUSETYPE_MODE_block of flats          -0.040592\n",
      "AMT_GOODS_PRICE                        -0.039647\n",
      "EMERGENCYSTATE_MODE                    -0.039408\n",
      "REGION_POPULATION_RELATIVE             -0.037229\n",
      "ELEVATORS_AVG                          -0.034202\n",
      "ELEVATORS_MEDI                         -0.033866\n",
      "FLOORSMIN_AVG                          -0.033620\n",
      "FLOORSMIN_MEDI                         -0.033401\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr = train.corr()['TARGET'].sort_values()\n",
    "print(\"Negatively correlated features are:\\n\",corr.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positively correlated features are:\n",
      " NAME_HOUSING_TYPE_With parents                       0.029965\n",
      "OCCUPATION_TYPE_Drivers                              0.030303\n",
      "DEF_60_CNT_SOCIAL_CIRCLE                             0.031295\n",
      "DEF_30_CNT_SOCIAL_CIRCLE                             0.032261\n",
      "LIVE_CITY_NOT_WORK_CITY                              0.032517\n",
      "OWN_CAR_AGE                                          0.037611\n",
      "DAYS_REGISTRATION                                    0.041976\n",
      "OCCUPATION_TYPE_Laborers                             0.043017\n",
      "FLAG_DOCUMENT_3                                      0.044341\n",
      "REG_CITY_NOT_LIVE_CITY                               0.044394\n",
      "FLAG_EMP_PHONE                                       0.045984\n",
      "NAME_EDUCATION_TYPE_Secondary / secondary special    0.049822\n",
      "REG_CITY_NOT_WORK_CITY                               0.050992\n",
      "DAYS_ID_PUBLISH                                      0.051457\n",
      "CODE_GENDER                                          0.054710\n",
      "DAYS_LAST_PHONE_CHANGE                               0.055220\n",
      "NAME_INCOME_TYPE_Working                             0.057483\n",
      "REGION_RATING_CLIENT                                 0.058901\n",
      "REGION_RATING_CLIENT_W_CITY                          0.060895\n",
      "TARGET                                               1.000000\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Positively correlated features are:\\n\",corr.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Engineered Treaining Data: (307507, 219)\n",
      "Shape of the Engineered Test Data: (48744, 219)\n",
      "First 15 Engineered Features: ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'NAME_EDUCATION_TYPE_Higher education', 'ORGANIZATION_TYPE_XNA', 'Birth_ANOMALY', 'FLOORSMAX_AVG', 'EXT_SOURCE_1^2', 'EXT_SOURCE_1 EXT_SOURCE_2', 'EXT_SOURCE_1 EXT_SOURCE_3', 'EXT_SOURCE_1 DAYS_BIRTH', 'EXT_SOURCE_1 DAYS_EMPLOYED', 'EXT_SOURCE_1 NAME_EDUCATION_TYPE_Higher education']\n",
      " Shape of train data before alinging: (307507, 458) \n",
      " Shape of test data before alinging: (48744, 457)\n",
      " Shape of train data after alinging: (307507, 458) \n",
      " Shape of test data after alinging: (48744, 457)\n"
     ]
    }
   ],
   "source": [
    "def features_engd(features, df_train, df_test, degree):\n",
    "    \"\"\" Features are given as a list.\"\"\"\n",
    "    df_train_eng = df_train[features]\n",
    "    df_test_eng = df_test[features]\n",
    "    \n",
    "    # Imputations\n",
    "    imputer = Imputer(strategy='mean')\n",
    "    # Instantiating polynomialfeaures\n",
    "    pf = PolynomialFeatures(degree, include_bias =False)\n",
    "    \n",
    "    df_train_eng =imputer.fit_transform(df_train_eng)\n",
    "    df_train_eng =pf.fit_transform(df_train_eng)\n",
    "    \n",
    "    df_test_eng =imputer.transform(df_test_eng)\n",
    "    df_test_eng =pf.transform(df_test_eng)\n",
    "    print(\"Shape of the Engineered Treaining Data: {}\".format(df_train_eng.shape))\n",
    "    print(\"Shape of the Engineered Test Data: {}\".format(df_test_eng.shape))\n",
    "    print(\"First 15 Engineered Features: {}\".format(pf.get_feature_names(input_features = features)[:15]))\n",
    "    \n",
    "    # Converting the engineered features into a data frame\n",
    "    df_train_eng = pd.DataFrame(df_train_eng, columns=pf.get_feature_names(input_features = features))\n",
    "    df_test_eng = pd.DataFrame(df_test_eng, columns=pf.get_feature_names(input_features = features))\n",
    "\n",
    "        \n",
    "    # Now merging the engineered dataframes\n",
    "    df_train_eng[\"SK_ID_CURR\"] =df_train[\"SK_ID_CURR\"]\n",
    "    df_test_eng[\"SK_ID_CURR\"] =df_test[\"SK_ID_CURR\"]\n",
    "    \n",
    "    \n",
    "    df_train = df_train.merge(df_train_eng, how= \"left\", on = \"SK_ID_CURR\")\n",
    "    df_test = df_test.merge(df_test_eng, how= \"left\", on = \"SK_ID_CURR\")\n",
    "        \n",
    "    # Aligning the engineered train and test data\n",
    "    if df_train.shape != df_test.shape:\n",
    "        df_train, df_test = align(df_train, df_test)\n",
    "    \n",
    "    # Adding the \"TARGET\" features to the engineered dataframe \n",
    "    df_train_eng[\"TARGET\"] =df_train[\"TARGET\"]\n",
    "    \n",
    "    return df_train_eng, df_test_eng, df_train, df_test\n",
    "\n",
    "features = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3',\n",
    "            \"DAYS_BIRTH\",\"DAYS_EMPLOYED\", \"NAME_EDUCATION_TYPE_Higher education\",\n",
    "            \"ORGANIZATION_TYPE_XNA\", \"Birth_ANOMALY\",\"FLOORSMAX_AVG\"]\n",
    "\n",
    "train_eng, test_eng, df_eng_train, df_eng_test = features_engd(features, train, test, degree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eng_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-79bf31454001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m eng_fts = [\"EXT_SOURCE_2 EXT_SOURCE_3\",\"EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3\",\n\u001b[1;32m      2\u001b[0m            \"EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH\", \"EXT_SOURCE_2^2 EXT_SOURCE_3\", \"EXT_SOURCE_2 EXT_SOURCE_3^2\"]\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_train_eng2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test_eng2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_engd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meng_fts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'eng_train' is not defined"
     ]
    }
   ],
   "source": [
    "eng_fts = [\"EXT_SOURCE_2 EXT_SOURCE_3\",\"EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3\",\n",
    "           \"EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH\", \"EXT_SOURCE_2^2 EXT_SOURCE_3\", \"EXT_SOURCE_2 EXT_SOURCE_3^2\"]\n",
    "df_train_eng2, df_test_eng2, eng_train2, eng_test2 = features_engd(eng_fts, eng_train, eng_test, degree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(train, test, file_name= \"log_reg\", C=1):\n",
    "# Here I am building a pipeline\n",
    "    test = train[\"TARGET\"].values\n",
    "    train = train.drop(\"TARGET\", axis=1).values\n",
    "\n",
    "    test = pd.get_dummies(test).values\n",
    "    pl = Pipeline([\n",
    "        (\"imputaton\", Imputer(strategy=\"median\")),\n",
    "        (\"scale\", MinMaxScaler(feature_range=(0, 1))),\n",
    "        (\"clf\", OneVsRestClassifier(estimator=LogisticRegression(C=C,class_weight=None,\n",
    "                                                                 dual=False, fit_intercept=True,\n",
    "                                                                 intercept_scaling=1, max_iter=100,\n",
    "                                                                 multi_class='ovr', n_jobs=1, \n",
    "                                                                 penalty='l2', random_state=4,\n",
    "                                                                 solver='liblinear', tol=0.0001, \n",
    "                                                                 verbose=0, warm_start=False)))\n",
    "    ])\n",
    "    pl.fit(trn,trt)\n",
    "    proba = pl.predict_proba(test)\n",
    "    submission = test[[\"SK_ID_CURR\"]]\n",
    "    submission[\"TARGET\"]  =proba[:,1]\n",
    "    submission = submission.to_csv(file_name + '.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg_rocauc(train, C=1):\n",
    "# Here I am building a pipeline\n",
    "    test = train[\"TARGET\"].values\n",
    "    train = train.drop(\"TARGET\", axis=1).values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train,test,\n",
    "                                                        test_size=0.2,\n",
    "                                                        stratify=test,\n",
    "                                                        random_state= 42)\n",
    "    #trt = pd.get_dummies(trt).values\n",
    "    pl = Pipeline([\n",
    "        (\"imputaton\", Imputer(strategy=\"median\")),\n",
    "        (\"scale\", MinMaxScaler(feature_range=(0, 1))),\n",
    "        (\"clf\", OneVsRestClassifier(estimator=LogisticRegression(C=C,class_weight=None,\n",
    "                                                                 dual=False, fit_intercept=True,\n",
    "                                                                 intercept_scaling=1, max_iter=100,\n",
    "                                                                 multi_class='ovr', n_jobs=1, \n",
    "                                                                 penalty='l2', random_state=4,\n",
    "                                                                 solver='liblinear', tol=0.0001, \n",
    "                                                                 verbose=0, warm_start=False)))\n",
    "    ])\n",
    "    pl.fit(X_train, y_train)\n",
    "    y_proba = pl.predict_proba(X_test)[:,1]\n",
    "    rocauc = roc_auc_score(y_test, y_proba)\n",
    "    print(\"ROC_AUC Score is {}\".format(rocauc))\n",
    "    return rocauc\n",
    "    #submission = test[[\"SK_ID_CURR\"]]\n",
    "    #submission[\"TARGET\"]  =proba[:,1]\n",
    "    #submission = submission.to_csv(file_name + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train.TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC Score is 0.7510089748120818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7510089748120818"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_rocauc(eng_train, C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC Score is 0.7510514312629597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7510514312629597"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_rocauc(eng_train2, C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier from sklearn.tree\n",
    "\n",
    "\n",
    "\n",
    "def decision_tree_rocauc(train):\n",
    "    test = train[\"TARGET\"].values\n",
    "    train = train.drop(\"TARGET\", axis=1).values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train,test,\n",
    "                                                        test_size=0.2,\n",
    "                                                        stratify=test,\n",
    "                                                        random_state= 42)\n",
    "    # Instantiating a DecisionTreeClassifier 'dt' with a maximum depth of 6\n",
    "    dt = DecisionTreeClassifier(max_depth =4,criterion=\"gini\", random_state=43, class_weight =\"balanced\")\n",
    "    \n",
    "    pl = Pipeline([\n",
    "    (\"imputaton\", Imputer(strategy=\"median\")),\n",
    "    (\"scale\", MinMaxScaler(feature_range=(0, 1))),\n",
    "    (\"clf\", OneVsRestClassifier(estimator=dt))\n",
    "    ])\n",
    "    \n",
    "    pl.fit(X_train, y_train)\n",
    "    y_proba = pl.predict_proba(X_test)[:,1]\n",
    "    rocauc = roc_auc_score(y_test, y_proba)\n",
    "    print(\"ROC_AUC Score is {}\".format(rocauc))\n",
    "    return y_proba\n",
    "\n",
    "# Diagnosing bias-variance problem: to see how well our model fits data(i.e. if our model underfits or overfits the data)\n",
    "\n",
    "def diagnose_bias_varaince(train):\n",
    "    imputer= Imputer(strategy =\"mean\")\n",
    "\n",
    "    \n",
    "    test = train[\"TARGET\"]\n",
    "    train = train.drop(\"TARGET\", axis=1)\n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train,test,\n",
    "                                                        test_size=0.2,\n",
    "                                                        stratify=test,\n",
    "                                                        random_state= 42)\n",
    "    pl = Pipeline([\n",
    "    (\"imputaton\", Imputer(strategy=\"median\")),\n",
    "    (\"scale\", MinMaxScaler(feature_range=(0, 1)))\n",
    "    ])\n",
    "    \n",
    "    X_train = pl.fit_transform(X_train)\n",
    "    X_test = pl.transform(X_test)\n",
    "    \n",
    "    # Instantiating a DecisionTreeClassifier 'dt' with a maximum depth of 6\n",
    "    \n",
    "    dt = DecisionTreeClassifier(max_depth =4,criterion=\"gini\",\n",
    "                                 random_state=43, class_weight =\"balanced\")\n",
    "    # Calculate cv scores\n",
    "    ROC_CV_scores = cross_val_score(dt, X_train, y_train, cv=2, \n",
    "                                  scoring='roc_auc', \n",
    "                                  n_jobs=-1)\n",
    "    #min_samples_leaf=0.1,\n",
    "    # Compute the 10-folds ROC_CV\n",
    "    ROC_CV = ROC_CV_scores\n",
    "    ROC_CV_mean = ROC_CV_scores.mean()\n",
    "\n",
    "    # Print ROC_CV\n",
    "    print('ROC_CV_mean: {:.2f}'.format(ROC_CV_mean))\n",
    "    \n",
    "    # Fit dt to the training set\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels of the training set\n",
    "    y_pred = dt.predict(X_train)\n",
    "    \n",
    "    ROC_train = roc_auc_score(y_train, y_pred)\n",
    "    print(\"ROC_train: {:.2f}\".format(ROC_train))\n",
    "    \n",
    "    #y_proba = pl.predict_proba(X_test)[:,1]\n",
    "\n",
    "    return ROC_CV, ROC_CV_mean, ROC_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_CV_mean: 0.69\n",
      "ROC_train: 0.50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.68965739, 0.68310577, 0.68644907, 0.6740724 , 0.67802664,\n",
       "        0.69459941, 0.69250055, 0.68221918, 0.69067273, 0.69700731]),\n",
       " 0.6868310462260004,\n",
       " 0.5)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max_depth =7,criterion=\"gini\",#min_samples_leaf=0.26,\n",
    "diagnose_bias_varaince(df_eng_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our model overfitted the data!\n",
    "\n",
    "    Over fitting occurs when the model captures the noise and the outliers in the data along with the underlying pattern. These models usually have high variance and low bias. These models are usually complex like Decision Trees, SVM or Neural Networks which are prone to over fitting.\n",
    "\n",
    "    Under fitting occurs when the model is unable to capture the underlying pattern of the data. These models usually have a low variance and a high bias. These models are usually simple which are unable to capture the complex patterns in the data like Linear and Logistic Regressions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_CV_mean: 0.69\n",
      "ROC_train: 0.50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.68965739, 0.68310577, 0.68644907, 0.6740724 , 0.67802664,\n",
       "        0.69459941, 0.69250055, 0.68221918, 0.69067273, 0.69700731]),\n",
       " 0.6868310462260004,\n",
       " 0.5)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's decrease the max_depth\n",
    "#max_depth =5,criterion=\"gini\",#min_samples_leaf=0.26,\n",
    "diagnose_bias_varaince(df_eng_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_CV_mean: 0.69\n",
      "ROC_train: 0.50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.68965739, 0.68310577, 0.68644907, 0.6740724 , 0.67802664,\n",
       "        0.69459941, 0.69250055, 0.68221918, 0.69067273, 0.69700731]),\n",
       " 0.6868310462260004,\n",
       " 0.5)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's decrease the max_depth\n",
    "#max_depth =12,criterion=\"gini\",#min_samples_leaf=0.26,\n",
    "diagnose_bias_varaince(df_eng_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_CV_mean: 0.67\n",
      "ROC_train: 0.74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.66462286, 0.67136321]), 0.6679930347460612, 0.7373405412431122)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's decrease the max_depth\n",
    "#max_depth =3,criterion=\"gini\",#min_samples_leaf=0.26,\n",
    "diagnose_bias_varaince(df_eng_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_CV_mean: 0.72\n",
      "ROC_train: 0.66\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.71136419, 0.7203733 ]), 0.7158687403258506, 0.6600785169675889)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnose_bias_varaince(df_eng_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC Score is 0.7212751473338236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.49715591, 0.25093503, 0.82372626, ..., 0.53069744, 0.65081912,\n",
       "       0.65081912])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_rocauc(df_eng_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Model\n",
    "def ensemble_model(train, sample =1000):\n",
    "    \n",
    "    train = train.sample(sample, random_state =3)\n",
    "    \n",
    "    test = train[\"TARGET\"]\n",
    "    train = train.drop(\"TARGET\", axis=1)\n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train,test,\n",
    "                                                        test_size=0.2,\n",
    "                                                        stratify=test,\n",
    "                                                        random_state= 42)\n",
    "    pl = Pipeline([\n",
    "    (\"imputaton\", Imputer(strategy=\"median\")),\n",
    "    (\"scale\", MinMaxScaler(feature_range=(0, 1)))\n",
    "    ])\n",
    "    \n",
    "    X_train = pl.fit_transform(X_train)\n",
    "    X_test = pl.transform(X_test)\n",
    "    \n",
    "    # Set seed for reproducibility\n",
    "    SEED=1\n",
    "\n",
    "    # Instantiate lr\n",
    "    lr = LogisticRegression(random_state=SEED)\n",
    "    # Instantiate knn\n",
    "    knn = KNN(n_neighbors=35)\n",
    "    # Instantiate dt\n",
    "    dt = DecisionTreeClassifier(max_depth =6, criterion=\"gini\",\n",
    "                                class_weight =\"balanced\",\n",
    "                                min_samples_leaf=0.13, \n",
    "                                random_state=SEED)\n",
    "    #Instantiate svm\n",
    "    svm = SVC(probability =True)\n",
    "\n",
    "    # Define the list classifiers\n",
    "    classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn),\n",
    "                   ('Classification Tree', dt), (\"Support Vector Machine\", svm)]\n",
    "\n",
    "    # Iterate over the pre-defined list of classifiers\n",
    "    for clf_name, clf in classifiers:    \n",
    "\n",
    "        # Fit clf to the training set\n",
    "        clf.fit(X_train, y_train)    \n",
    "\n",
    "        # Predict y_pred\n",
    "\n",
    "        y_proba = clf.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        rocauc_score = roc_auc_score(y_test, y_proba)\n",
    "        \n",
    "        # Evaluate clf's accuracy on the test set\n",
    "        print('{:s} : {:.3f}'.format(clf_name, rocauc_score))\n",
    "\n",
    "    # Instantiate a VotingClassifier vc \n",
    "    vc = VotingClassifier(estimators=classifiers, voting =\"soft\", n_jobs =-1)     \n",
    "\n",
    "    # Fit vc to the training set\n",
    "    vc.fit(X_train, y_train)   \n",
    "\n",
    "    # Evaluate the test set predictions\n",
    "    y_proba = vc.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # Calculate accuracy score\n",
    "    rocauc_score = roc_auc_score(y_test, y_proba)\n",
    "    print('Voting Classifier: {:.3f}'.format(rocauc_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.689\n",
      "K Nearest Neighbours : 0.524\n",
      "Classification Tree : 0.636\n",
      "Support Vector Machine : 0.565\n",
      "Voting Classifier: 0.645\n"
     ]
    }
   ],
   "source": [
    "ensemble_model(df_eng_train, sample =10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_classifier(train, sample =1000):\n",
    "    \n",
    "    train = train.sample(sample, random_state =3)\n",
    "    test = train[\"TARGET\"]\n",
    "    train = train.drop(\"TARGET\", axis=1)\n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train,test,\n",
    "                                                        test_size=0.2,\n",
    "                                                        stratify=test,\n",
    "                                                        random_state= 42)\n",
    "    pl = Pipeline([\n",
    "    (\"imputaton\", Imputer(strategy=\"median\")),\n",
    "    (\"scale\", MinMaxScaler(feature_range=(0, 1)))\n",
    "    ])\n",
    "    \n",
    "    X_train = pl.fit_transform(X_train)\n",
    "    X_test = pl.transform(X_test)\n",
    "    \n",
    "\n",
    "    # Instantiate dt\n",
    "    dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "    # Instantiate bc\n",
    "    bc = BaggingClassifier(base_estimator=dt,\n",
    "                           n_estimators=50,\n",
    "                           oob_score=True,\n",
    "                           random_state=1)\n",
    "    \n",
    "    # Fit bc to the training set\n",
    "    bc.fit(X_train, y_train)\n",
    "    # Predict test set labels\n",
    "    y_pred = bc.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # Evaluate acc_test\n",
    "    acc_test = accuracy_score(y_test, y_pred)\n",
    "    print('Test set accuracy of bc: {:.2f}'.format(acc_test))\n",
    "    \n",
    "    # Evaluate OOB accuracy\n",
    "    acc_oob = bc.oob_score_\n",
    "\n",
    "    # Print acc_test and acc_oob\n",
    "    print('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_classifier(train, sample =100):\n",
    "   \n",
    "    train_id = train[\"SK_ID_CURR\"]\n",
    "    train = train.sample(sample, random_state =3)\n",
    "    test = train[\"TARGET\"]\n",
    "    train = train.drop([\"TARGET\", \"SK_ID_CURR\"], axis=1)\n",
    "    df_train = train.copy()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train,test,\n",
    "                                                        test_size=0.2,\n",
    "                                                        stratify=test,\n",
    "                                                        random_state= 42)\n",
    "    pl = Pipeline([\n",
    "    (\"imputaton\", Imputer(strategy=\"median\")),\n",
    "    (\"scale\", MinMaxScaler(feature_range=(0, 1)))\n",
    "    ])\n",
    "    \n",
    "    X_train = pl.fit_transform(X_train)\n",
    "    X_test = pl.transform(X_test)\n",
    "    \n",
    "    \n",
    "    # Instantiate rf\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=25,max_depth =8,verbose =1,\n",
    "                           random_state=2,n_jobs=-1)\n",
    "                           \n",
    "    # Fit rf to the training set            \n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the test set labels\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Evaluate the test set RMSE\n",
    "    roc_test =roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    # Print rmse_test\n",
    "    print('Test set ROCAUC of RandomForest: {:.2f}'.format(roc_test))\n",
    "    \n",
    "    # Create a pd.Series of features importances\n",
    "    importances = pd.Series(data=rf.feature_importances_,\n",
    "                            index= df_train.columns)\n",
    "\n",
    "    # Sort importances\n",
    "    importances_sorted = importances.sort_values(ascending=True)\n",
    "\n",
    "    # Draw a horizontal barplot of importances_sorted\n",
    "    importances_sorted[-20:].plot(kind='barh', color='lightgreen')\n",
    "    plt.title('Features Importances')\n",
    "\n",
    "    plt.show()\n",
    "    return importances_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  6.9min finished\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set ROCAUC of RandomForest: 0.72\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ORGANIZATION_TYPE_Transport: type 1                  0.000000\n",
       "ORGANIZATION_TYPE_Religion                           0.000000\n",
       "ORGANIZATION_TYPE_Mobile                             0.000000\n",
       "NAME_EDUCATION_TYPE_Higher education_y               0.000000\n",
       "ORGANIZATION_TYPE_XNA_y                              0.000000\n",
       "Birth_ANOMALY_y                                      0.000000\n",
       "NAME_INCOME_TYPE_Businessman                         0.000000\n",
       "ORGANIZATION_TYPE_Insurance                          0.000000\n",
       "ORGANIZATION_TYPE_Security                           0.000000\n",
       "NAME_INCOME_TYPE_Student                             0.000000\n",
       "DAYS_BIRTH ORGANIZATION_TYPE_XNA Birth_ANOMALY       0.000000\n",
       "Birth_ANOMALY FLOORSMAX_AVG                          0.000000\n",
       "Birth_ANOMALY^2                                      0.000000\n",
       "ORGANIZATION_TYPE_XNA FLOORSMAX_AVG                  0.000000\n",
       "ORGANIZATION_TYPE_Industry: type 5                   0.000000\n",
       "EXT_SOURCE_2 ORGANIZATION_TYPE_XNA                   0.000000\n",
       "ORGANIZATION_TYPE_Industry: type 12                  0.000000\n",
       "ORGANIZATION_TYPE_Industry: type 7                   0.000000\n",
       "NAME_FAMILY_STATUS_Separated                         0.000000\n",
       "ORGANIZATION_TYPE_Security Ministries                0.000000\n",
       "FLAG_DOCUMENT_19                                     0.000000\n",
       "WEEKDAY_APPR_PROCESS_START_MONDAY                    0.000000\n",
       "FLAG_DOCUMENT_4                                      0.000000\n",
       "EXT_SOURCE_3 DAYS_EMPLOYED ORGANIZATION_TYPE_XNA     0.000000\n",
       "FLAG_DOCUMENT_6                                      0.000000\n",
       "FLAG_DOCUMENT_10                                     0.000000\n",
       "ORGANIZATION_TYPE_XNA_x                              0.000000\n",
       "FLAG_DOCUMENT_11                                     0.000000\n",
       "AMT_REQ_CREDIT_BUREAU_HOUR                           0.000000\n",
       "FLAG_DOCUMENT_12                                     0.000000\n",
       "                                                       ...   \n",
       "EXT_SOURCE_2 EXT_SOURCE_3 DAYS_EMPLOYED              0.002642\n",
       "EXT_SOURCE_2^2 DAYS_EMPLOYED                         0.002670\n",
       "EXT_SOURCE_1 EXT_SOURCE_3 DAYS_EMPLOYED              0.002753\n",
       "EXT_SOURCE_3 DAYS_EMPLOYED FLOORSMAX_AVG             0.002813\n",
       "EXT_SOURCE_2^2 FLOORSMAX_AVG                         0.002887\n",
       "EXT_SOURCE_1^2 DAYS_BIRTH                            0.002985\n",
       "EXT_SOURCE_1 DAYS_BIRTH DAYS_EMPLOYED                0.003050\n",
       "DAYS_BIRTH FLOORSMAX_AVG^2                           0.003250\n",
       "EXT_SOURCE_2 DAYS_BIRTH^2                            0.003323\n",
       "EXT_SOURCE_2 EXT_SOURCE_3 FLOORSMAX_AVG              0.003593\n",
       "EXT_SOURCE_1^2 DAYS_EMPLOYED                         0.003657\n",
       "EXT_SOURCE_2^2 DAYS_BIRTH                            0.004286\n",
       "NAME_EDUCATION_TYPE_Secondary / secondary special    0.004313\n",
       "FLAG_DOCUMENT_3                                      0.004481\n",
       "EXT_SOURCE_2^2 EXT_SOURCE_3                          0.004562\n",
       "HOUR_APPR_PROCESS_START                              0.004943\n",
       "REGION_POPULATION_RELATIVE                           0.005099\n",
       "CODE_GENDER                                          0.006126\n",
       "AMT_GOODS_PRICE                                      0.006133\n",
       "DAYS_LAST_PHONE_CHANGE                               0.006921\n",
       "AMT_INCOME_TOTAL                                     0.008005\n",
       "AMT_CREDIT                                           0.010017\n",
       "DAYS_ID_PUBLISH                                      0.010825\n",
       "DAYS_REGISTRATION                                    0.010943\n",
       "AMT_ANNUITY                                          0.011573\n",
       "DAYS_BIRTH_x                                         0.022216\n",
       "DAYS_EMPLOYED_x                                      0.027752\n",
       "EXT_SOURCE_1_x                                       0.061199\n",
       "EXT_SOURCE_2_x                                       0.254152\n",
       "EXT_SOURCE_3_x                                       0.258668\n",
       "Length: 456, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_classifier(df_eng_train, sample =200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    " def adaboost(train, sample =10000, estimator =10, learning_rate =1):\n",
    "    \n",
    "    train_id = train[\"SK_ID_CURR\"]\n",
    "    train = train.sample(sample, random_state =3)\n",
    "    test = train[\"TARGET\"]\n",
    "    train = train.drop([\"TARGET\", \"SK_ID_CURR\"], axis=1)\n",
    "    df_train = train.copy()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train,test,\n",
    "                                                        test_size=0.2,\n",
    "                                                        stratify=test,\n",
    "                                                        random_state= 42)\n",
    "    pl = Pipeline([\n",
    "    (\"imputaton\", Imputer(strategy=\"median\")),\n",
    "    (\"scale\", MinMaxScaler(feature_range=(0, 1)))\n",
    "    ])\n",
    "    \n",
    "    X_train = pl.fit_transform(X_train)\n",
    "    X_test = pl.transform(X_test)\n",
    "\n",
    "    # Instantiate dt\n",
    "    dt = DecisionTreeClassifier(max_depth=2, random_state=1)\n",
    "\n",
    "    # Instantiate ada\n",
    "    ada = AdaBoostClassifier(base_estimator=dt, n_estimators=estimator,\n",
    "                             learning_rate =learning_rate, random_state=1)\n",
    "    \n",
    "    # Fit ada to the training set\n",
    "    ada.fit(X_train, y_train)\n",
    "\n",
    "    # Compute the probabilities of obtaining the positive class\n",
    "    y_pred_proba = ada.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # Evaluate test-set roc_auc_score\n",
    "    ada_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Print roc_auc_score\n",
    "    print('ROC AUC score: {:.2f}'.format(ada_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.69\n"
     ]
    }
   ],
   "source": [
    "adaboost(df_eng_train, sample =100000, n_estimatos =300, learning_rate =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting(train, sample =10000, n_estimators =10, learning_rate = 1):\n",
    "\n",
    "    train_id = train[\"SK_ID_CURR\"]\n",
    "    train = train.sample(sample, random_state =3)\n",
    "    test = train[\"TARGET\"]\n",
    "    train = train.drop([\"TARGET\", \"SK_ID_CURR\"], axis=1)\n",
    "    df_train = train.copy()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train,test,\n",
    "                                                        test_size=0.2,\n",
    "                                                        stratify=test,\n",
    "                                                        random_state= 42)\n",
    "    pl = Pipeline([\n",
    "    (\"imputaton\", Imputer(strategy=\"median\")),\n",
    "    (\"scale\", MinMaxScaler(feature_range=(0, 1)))\n",
    "    ])\n",
    "    \n",
    "    X_train = pl.fit_transform(X_train)\n",
    "    X_test = pl.transform(X_test)\n",
    "    \n",
    "    \n",
    "    gb = GradientBoostingClassifier(max_depth=4,subsample=0.7,\n",
    "                                    max_features=0.75,n_estimators=n_estimators, \n",
    "                                    learning_rate= learning_rate,\n",
    "                                    verbose =True, random_state=2)\n",
    "    \n",
    "    # Fit ada to the training set\n",
    "    gb.fit(X_train, y_train)\n",
    "\n",
    "    # Compute the probabilities of obtaining the positive class\n",
    "    y_pred_proba = gb.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # Evaluate test-set roc_auc_score\n",
    "    gb_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Print roc_auc_score\n",
    "    print('ROC AUC score: {:.2f}'.format(gb_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.5505           0.0082            4.88m\n",
      "         2           0.5399           0.0067            4.46m\n",
      "         3           0.5366           0.0051            4.24m\n",
      "         4           0.5307           0.0043            4.10m\n",
      "         5           0.5265           0.0034            4.00m\n",
      "         6           0.5227           0.0027            3.91m\n",
      "         7           0.5250           0.0024            3.84m\n",
      "         8           0.5202           0.0018            3.80m\n",
      "         9           0.5211           0.0018            3.75m\n",
      "        10           0.5187           0.0015            3.69m\n",
      "        20           0.4988           0.0001            3.21m\n",
      "        30           0.4951           0.0003            2.79m\n",
      "        40           0.4924          -0.0000            2.38m\n",
      "        50           0.4904          -0.0000            1.98m\n",
      "        60           0.4841          -0.0001            1.67m\n",
      "        70           0.4737          -0.0001            1.32m\n",
      "        80           0.4704          -0.0004           52.47s\n",
      "        90           0.4719          -0.0001           27.05s\n",
      "       100           0.4700          -0.0001            0.00s\n",
      "ROC AUC score: 0.74\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting(df_eng_train, sample =100000, n_estimators =100, learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.5496           0.0090          180.55m\n",
      "         2           0.5396           0.0068          151.38m\n",
      "         3           0.5368           0.0055          115.59m\n",
      "         4           0.5318           0.0042           95.64m\n",
      "         5           0.5284           0.0035           84.14m\n",
      "         6           0.5266           0.0028           75.25m\n",
      "         7           0.5250           0.0025           69.18m\n",
      "         8           0.5195           0.0021           66.53m\n",
      "         9           0.5208           0.0019           63.14m\n",
      "        10           0.5176           0.0015           74.01m\n",
      "        20           0.5029           0.0006           57.86m\n",
      "        30           0.4980           0.0004           50.11m\n",
      "        40           0.4949           0.0002           42.71m\n",
      "        50           0.4897           0.0001           37.66m\n",
      "        60           0.4897           0.0000           33.89m\n",
      "        70           0.4860           0.0000           30.86m\n",
      "        80           0.4840          -0.0001           28.40m\n",
      "        90           0.4776          -0.0000           26.33m\n",
      "       100           0.4766          -0.0002           24.27m\n",
      "       200           0.4612          -0.0001           11.21m\n",
      "       300           0.4555          -0.0001            0.00s\n",
      "ROC AUC score: 0.75\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting(df_eng_train, sample =200000, n_estimators =300, learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': False,\n",
       " 'random_state': 1,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "dt.get_params()\n",
    "params_dt = {'class_weight': None,\n",
    " 'criterion': 'gini',\n",
    " 'max_depth': None,\n",
    " 'max_features': None,\n",
    " 'max_leaf_nodes': None,\n",
    " 'min_impurity_decrease': 0.0,\n",
    " 'min_impurity_split': None,\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 2,\n",
    " 'min_weight_fraction_leaf': 0.0,\n",
    " 'presort': False,\n",
    " 'random_state': 1,\n",
    " 'splitter': 'best'}\n",
    "params_dt = {\n",
    "             'max_depth': [2, 4, 6,8,10],\n",
    "             'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate grid_dt\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring='roc_auc',\n",
    "                       cv=5,\n",
    "                       n_jobs=-1)\n",
    "# Extract the best estimator\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute test_roc_auc\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def GridSearchRF(train)\n",
    "rf = RandomForestRegressor(n_estimators=25)\n",
    "params_rf = {\n",
    "             'n_estimators': [100, 350, 500],\n",
    "             'max_features': ['log2', 'auto', 'sqrt'],\n",
    "             'min_samples_leaf': [2, 10, 30], \n",
    "             }\n",
    "# Instantiate grid_rf\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=3,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)\n",
    "# Extract the best estimator\n",
    "best_model = grid_rf.best_estimator_\n",
    "\n",
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute test_roc_auc\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
